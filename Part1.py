import numpy as np
import pandas as pd
import time


ALLFEATURES = ['zero_cross_rate_mean', 'zero_cross_rate_std',       'rmse_mean', 'rmse_var', 'spectral_centroid_mean',
       'spectral_centroid_var', 'spectral_bandwidth_mean',       'spectral_bandwidth_var', 'spectral_rolloff_mean',
       'spectral_rolloff_var', 'spectral_contrast_mean',       'spectral_contrast_var', 'spectral_flatness_mean',       
       'spectral_flatness_var', 'chroma_stft_1_mean', 'chroma_stft_2_mean',
       'chroma_stft_3_mean', 'chroma_stft_4_mean', 'chroma_stft_5_mean',
       'chroma_stft_6_mean', 'chroma_stft_7_mean', 'chroma_stft_8_mean',
       'chroma_stft_9_mean', 'chroma_stft_10_mean', 'chroma_stft_11_mean',
       'chroma_stft_12_mean', 'chroma_stft_1_std', 'chroma_stft_2_std',
       'chroma_stft_3_std', 'chroma_stft_4_std', 'chroma_stft_5_std',
       'chroma_stft_6_std', 'chroma_stft_7_std', 'chroma_stft_8_std',
       'chroma_stft_9_std', 'chroma_stft_10_std', 'chroma_stft_11_std',
       'chroma_stft_12_std', 'tempo', 'mfcc_1_mean', 'mfcc_2_mean',
       'mfcc_3_mean', 'mfcc_4_mean', 'mfcc_5_mean', 'mfcc_6_mean',
       'mfcc_7_mean', 'mfcc_8_mean', 'mfcc_9_mean', 'mfcc_10_mean',
       'mfcc_11_mean', 'mfcc_12_mean', 'mfcc_1_std', 'mfcc_2_std',
       'mfcc_3_std', 'mfcc_4_std', 'mfcc_5_std', 'mfcc_6_std', 'mfcc_7_std',
       'mfcc_8_std', 'mfcc_9_std', 'mfcc_10_std', 'mfcc_11_std', 'mfcc_12_std',
       ]

GENREMAP = {"pop": 0, "disco": 1, "metal" : 2, "classical" : 3, "rock" : 4,
            "blues" : 5, "reggae" : 6, "hiphop" : 7, "country" : 8, "jazz" : 9}

genre2 = {"pop": 0, "disco": 1, "metal" : 2, "classical" : 3}
# ClassData5  = pd.read_table("Classification music(1)\Classification music\GenreClassData_5s.txt")
# ClassData10 = pd.read_table("Classification music(1)\Classification music\GenreClassData_10s.txt")
ClassData30 = pd.read_table("Classification music(1)\Classification music\GenreClassData_30s.txt")

# Divide data into testing sets and training sets
trainingSet30 = ClassData30.query("Type == 'Train'")    # Training set
testingSet30 = ClassData30.query("Type == 'Test'")      # Testing set

# Task 1
    # (A) Design a k-NN classifier (with k=5) for all ten genres using only:
    # spectral_rolloff_mean, mfcc_1_mean, sepctral_centroid_mean and tempo
    # I.e find the 5 closest references and choose the class with the most 
    # references

    # Training a NN classifier would be the same as choosing good references
    # The references in this case will be the entire training set. The distance
    # measure is the Euclidian dinstance

k = 5
# features = trainingSet30[['spectral_rolloff_mean', 'mfcc_1_mean', 'spectral_centroid_mean', 'tempo', 'Genre']]
references = trainingSet30[['spectral_rolloff_mean', 'mfcc_1_mean', 'spectral_centroid_mean', 'spectral_rolloff_var']]

def euclidianDistance(x, u):
    """Calculates the Euclidian distance between the input x and reference u
    
    Parameters
    ----------
    x : list(int)
        list of input values
    u : list(int)
        list of reference values
    """
    return np.matmul(np.transpose(x-u), (x-u))

def relativeEuclidian(x, u):
    """Calculates the relative distance between the input x and reference u
    
    Parameters
    ----------
    x : list(int)
        list of input values
    u : list(int)
        list of reference values
    """
    return np.matmul(np.transpose(np.divide((x-u),u)), np.divide((x-u),u))

def NNclassifier(data=ClassData30, 
        mapIndex=GENREMAP, 
        distance=euclidianDistance, 
        k=5, 
        features=['spectral_rolloff_mean', 'mfcc_1_mean', 'spectral_centroid_mean', 'tempo']):
    
    """A k-NN classifier for the data.


       Parameters
        ----------
        data : pd.Dataframe, optional
            A pandas dataframe containing the relevant data.
        mapIndex : list(tuple(str, int)), optional
            List of the tuple (Genre, index). Genre is a string of a genre in data.
            index is an integer that corresponds to the row number of Genre in the 
            generated confusion matrix
        distane : function, optional
            A function for the choice of similarity measure. Euclidian distance is
            the default and recommended in this implementation
        k : int
            Determines the k in k-NN classifier. Gives the number of most similar points
            to consider
        features : list(string), optional
            A list of the features the classifier should consider when deciding similarity.
            Need to correspond to keys in data 
    """
    # Create the reference set
    referenceSet = data.query("Type == 'Train'")
    referenceSet = referenceSet[referenceSet.Genre.isin(mapIndex.keys())]

    # Create the test set
    testSet = data.query("Type == 'Test'")
    testSet = testSet[testSet.Genre.isin(mapIndex.keys())]
    

    start = time.time()
    # The confusion matrix generated by the classifier
    confusionMatrix = pd.DataFrame(0, index=list(mapIndex.values()), columns=mapIndex.keys())

    
    for i in range(len(testSet)): # Iterate over all test points
        closestPoints = [(np.inf, 'Genre')] * k
        furthestPoint = (np.inf, 'Genre')
        
        # x is the test point to consider
        x = np.array(testSet.iloc[i, [testSet.columns.get_loc(c) for c in features]])
        
        for j in range(len(referenceSet)): # Iterate over all reference points
            # u is the refernce point to consider
            u = np.array(referenceSet.iloc[j, [referenceSet.columns.get_loc(c) for c in features]])
            # d is the distance/similarity between the test point and reference point
            d = distance(x, u)


            if d < furthestPoint[0]: # d is closer than the furthest of the k closest points
                # replace the furthest of the k points with d
                closestPoints.remove(furthestPoint)
                closestPoints.append((d, referenceSet.iloc[j, referenceSet.columns.get_loc("Genre")]))
                furthestPoint = max(closestPoints, key = lambda t : t[0]) # update the furthest point

        # Sort the closest k points to correctly resolve tiebreaks
        closestPoints.sort(key=lambda x : x[0])
        
        # count is a dictionary {genre : int} that counts how many times a genre is in the k closest points
        count = {}
        for z in range(len(closestPoints)):
            if closestPoints[z][1] in count.keys():
                count[closestPoints[z][1]] += 1
            else:
                count[closestPoints[z][1]] = 1

        classification = max(count, key=count.get) # Classification is the genre with the k closest points
        genre = testSet.iat[i, testSet.columns.get_loc("Genre")] # The actual genre at the point

        confusionMatrix.at[mapIndex[genre], classification] += 1    # Update the confusion matrix
    

    # The number of correct classifications is on the diagonal 
    correctClassifications = pd.Series(np.diag(confusionMatrix), index=[confusionMatrix.index, confusionMatrix.columns])
    num = correctClassifications.sum()
    errorRate = 1-num/confusionMatrix.sum().sum() # eer = 1 - correct/total
    end = time.time()
    print(end - start, 'Seconds')
    return errorRate, confusionMatrix 

# error, CM = NNclassifier()
# print('Estimated error rate for Task 1:', error)
# print('Confusion matrix for Task 1')
# print(CM)





 
